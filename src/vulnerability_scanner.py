#!/usr/bin/env python3
"""
Vulnerability Scanner for IHACPA Python Package Review Automation
Handles scanning multiple vulnerability databases for Python packages
Includes AI-powered CVE analysis using OpenAI API
"""

import asyncio
import aiohttp
import requests
import os
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
import logging
import re
from urllib.parse import urljoin, quote

try:
    from .ai_cve_analyzer import AICVEAnalyzer
except ImportError:
    try:
        from ai_cve_analyzer import AICVEAnalyzer
    except ImportError:
        AICVEAnalyzer = None


class VulnerabilityScanner:
    """Scanner for checking multiple vulnerability databases"""
    
    DATABASES = {
        'nist_nvd': {
            'name': 'NIST NVD',
            'base_url': 'https://services.nvd.nist.gov/rest/json/cves/2.0',
            'search_param': 'keywordSearch',
            'enabled': True
        },
        'mitre_cve': {
            'name': 'MITRE CVE',
            'base_url': 'https://cve.mitre.org/cgi-bin/cvekey.cgi',
            'search_param': 'keyword',
            'enabled': True
        },
        'snyk': {
            'name': 'SNYK',
            'base_url': 'https://security.snyk.io/vuln/pip',
            'search_param': 'package',
            'enabled': True
        },
        'exploit_db': {
            'name': 'Exploit Database',
            'base_url': 'https://www.exploit-db.com/search',
            'search_param': 'text',
            'enabled': True
        },
        'github_advisory': {
            'name': 'GitHub Security Advisory',
            'base_url': 'https://github.com/advisories',
            'search_param': 'query',
            'enabled': True
        }
    }
    
    def __init__(self, timeout: int = 30, max_retries: int = 3, rate_limit: float = 1.0, 
                 openai_api_key: Optional[str] = None, ai_enabled: bool = True,
                 azure_endpoint: Optional[str] = None, azure_model: Optional[str] = None):
        """Initialize vulnerability scanner"""
        self.timeout = timeout
        self.max_retries = max_retries
        self.rate_limit = rate_limit  # Seconds between requests
        self.session = None
        self.logger = logging.getLogger(__name__)
        self.last_request_time = {}
        
        # Initialize AI CVE analyzer
        self.ai_analyzer = None
        if ai_enabled and AICVEAnalyzer:
            try:
                # Get API version from environment if not passed
                azure_api_version = os.getenv('AZURE_OPENAI_API_VERSION')
                
                # Use environment variables if parameters not provided
                if not azure_model:
                    azure_model = os.getenv('AZURE_OPENAI_MODEL')
                if not azure_endpoint:
                    azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')
                if not openai_api_key:
                    openai_api_key = os.getenv('AZURE_OPENAI_KEY') or os.getenv('OPENAI_API_KEY')
                
                self.ai_analyzer = AICVEAnalyzer(
                    api_key=openai_api_key,
                    model=azure_model,
                    azure_endpoint=azure_endpoint,
                    api_version=azure_api_version
                )
                if self.ai_analyzer.is_enabled():
                    service_type = "Azure OpenAI" if self.ai_analyzer.is_azure else "Standard OpenAI"
                    self.logger.info(f"AI CVE analysis enabled using {service_type}")
                else:
                    self.logger.warning("AI CVE analysis disabled - configuration incomplete")
            except Exception as e:
                self.logger.error(f"Failed to initialize AI CVE analyzer: {e}")
                self.ai_analyzer = None
        else:
            self.logger.info("AI CVE analysis disabled")
        
    async def _rate_limited_request(self, database: str, url: str, params: Dict = None) -> Optional[Dict]:
        """Make rate-limited request to avoid overwhelming APIs"""
        current_time = datetime.now()
        
        if database in self.last_request_time:
            time_since_last = (current_time - self.last_request_time[database]).total_seconds()
            if time_since_last < self.rate_limit:
                await asyncio.sleep(self.rate_limit - time_since_last)
        
        self.last_request_time[database] = current_time
        
        if not self.session:
            self.session = aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.timeout))
        
        for attempt in range(self.max_retries):
            try:
                async with self.session.get(url, params=params) as response:
                    if response.status == 200:
                        return await response.json()
                    elif response.status == 404:
                        self.logger.debug(f"No data found for {url}")
                        return None
                    else:
                        self.logger.warning(f"HTTP {response.status} for {url}")
                        
            except asyncio.TimeoutError:
                self.logger.warning(f"Timeout on attempt {attempt + 1} for {url}")
                
            except aiohttp.ClientError as e:
                self.logger.error(f"Client error on attempt {attempt + 1} for {url}: {e}")
                
            except Exception as e:
                self.logger.error(f"Unexpected error for {url}: {e}")
                
            if attempt < self.max_retries - 1:
                await asyncio.sleep(2 ** attempt)
                
        return None
    
    def _build_search_urls(self, package_name: str) -> Dict[str, str]:
        """Build search URLs for all databases"""
        urls = {}
        
        # NIST NVD
        urls['nist_nvd'] = f"{self.DATABASES['nist_nvd']['base_url']}?keywordSearch={quote(package_name)}"
        
        # MITRE CVE
        urls['mitre_cve'] = f"{self.DATABASES['mitre_cve']['base_url']}?keyword={quote(package_name)}"
        
        # SNYK
        urls['snyk'] = f"{self.DATABASES['snyk']['base_url']}/{quote(package_name)}"
        
        # Exploit Database
        urls['exploit_db'] = f"{self.DATABASES['exploit_db']['base_url']}?text={quote(package_name)}"
        
        # GitHub Security Advisory
        urls['github_advisory'] = f"{self.DATABASES['github_advisory']['base_url']}?query={quote(f'ecosystem:pip {package_name}')}"
        
        return urls
    
    async def scan_nist_nvd(self, package_name: str, current_version: str = None) -> Dict[str, Any]:
        """Scan NIST NVD database with AI-powered analysis"""
        try:
            url = f"{self.DATABASES['nist_nvd']['base_url']}?keywordSearch={quote(package_name)}"
            
            # Check if AI analysis is available
            ai_result = None
            if self.ai_analyzer and self.ai_analyzer.is_enabled() and current_version:
                try:
                    self.logger.debug(f"Running AI NIST NVD analysis for {package_name} v{current_version}")
                    ai_result = await self.ai_analyzer.analyze_nist_nvd_result(
                        package_name=package_name,
                        current_version=current_version,
                        nist_nvd_url=url
                    )
                    self.logger.debug(f"AI NIST NVD analysis completed: {ai_result}")
                except Exception as e:
                    self.logger.error(f"AI NIST NVD analysis failed for {package_name}: {e}")
                    ai_result = f"AI analysis failed: {str(e)}"
            
            # Generate result based on AI analysis or fallback to manual review
            if ai_result and "AI analysis not available" not in ai_result and "AI analysis failed" not in ai_result:
                summary = self._standardize_no_risk_message('nist_nvd', ai_result)
                note = f"AI-powered NIST NVD analysis completed. Original URL for manual verification: {url}"
                self.logger.info(f"✅ AI NIST NVD analysis completed for {package_name} v{current_version}: {ai_result[:100]}...")
            else:
                # Fallback to basic API scanning for compatibility
                data = await self._rate_limited_request('nist_nvd', url)
                if not data:
                    summary = "None found"
                    note = 'NIST NVD search returned no results'
                else:
                    vulnerabilities = data.get('vulnerabilities', [])
                    results = []
                    
                    for vuln in vulnerabilities:
                        cve_data = vuln.get('cve', {})
                        cve_id = cve_data.get('id', '')
                        
                        # Check if vulnerability is actually related to the package
                        description = cve_data.get('descriptions', [{}])[0].get('value', '')
                        if package_name.lower() in description.lower():
                            severity = 'Unknown'
                            score = 'N/A'
                            
                            # Get CVSS score
                            metrics = cve_data.get('metrics', {})
                            cvss_v3 = metrics.get('cvssMetricV31', [])
                            if cvss_v3:
                                cvss_data = cvss_v3[0].get('cvssData', {})
                                score = cvss_data.get('baseScore', 'N/A')
                                severity = cvss_data.get('baseSeverity', 'Unknown')
                            
                            results.append({
                                'cve_id': cve_id,
                                'description': description[:200] + '...' if len(description) > 200 else description,
                                'severity': severity,
                                'score': score,
                                'published': cve_data.get('published', ''),
                                'modified': cve_data.get('lastModified', '')
                            })
                    
                    if results:
                        summary = f"Found {len(results)} vulnerabilities in NIST NVD"
                    else:
                        summary = "None found"
                    
                note = f"Manual review required - check {url}"
                if not self.ai_analyzer or not self.ai_analyzer.is_enabled():
                    note += " (AI analysis not available)"
                elif ai_result:
                    self.logger.warning(f"AI NIST NVD analysis failed for {package_name}: {ai_result[:100]}...")
                else:
                    self.logger.warning(f"No AI NIST NVD result for {package_name} v{current_version}")
            
            return {
                'database': 'NIST NVD',
                'package_name': package_name,
                'current_version': current_version,
                'search_url': url,
                'found_vulnerabilities': False,  # Will be updated by AI analysis parsing
                'vulnerability_count': 0,  # Will be updated by AI analysis parsing
                'vulnerabilities': [],
                'summary': summary,
                'ai_analysis': ai_result,
                'scanned_at': datetime.now().isoformat(),
                'note': note
            }
            
        except Exception as e:
            self.logger.error(f"Error scanning NIST NVD for {package_name}: {e}")
            return self._error_result('nist_nvd', package_name, str(e))
    
    async def scan_mitre_cve(self, package_name: str, current_version: str = None) -> Dict[str, Any]:
        """Scan MITRE CVE database with AI-powered analysis"""
        try:
            url = f"{self.DATABASES['mitre_cve']['base_url']}?keyword={quote(package_name)}"
            
            # Check if AI analysis is available
            ai_result = None
            if self.ai_analyzer and self.ai_analyzer.is_enabled() and current_version:
                try:
                    self.logger.debug(f"Running AI CVE analysis for {package_name} v{current_version}")
                    ai_result = await self.ai_analyzer.analyze_cve_result(
                        package_name=package_name,
                        current_version=current_version,
                        cve_lookup_url=url
                    )
                    self.logger.debug(f"AI analysis completed: {ai_result}")
                except Exception as e:
                    self.logger.error(f"AI CVE analysis failed for {package_name}: {e}")
                    ai_result = f"AI analysis failed: {str(e)}"
            
            # Generate result based on AI analysis or fallback to manual review
            if ai_result and "AI analysis not available" not in ai_result and "AI analysis failed" not in ai_result:
                summary = self._standardize_no_risk_message('mitre_cve', ai_result)
                note = f"AI-powered analysis completed. Original URL for manual verification: {url}"
                self.logger.info(f"✅ AI CVE analysis completed for {package_name} v{current_version}: {ai_result[:100]}...")
            else:
                summary = f"Manual review required - check {url}"
                note = 'MITRE CVE requires manual review of search results'
                if not self.ai_analyzer or not self.ai_analyzer.is_enabled():
                    note += " (AI analysis not available)"
                elif ai_result:
                    self.logger.warning(f"AI analysis failed for {package_name}: {ai_result[:100]}...")
                else:
                    self.logger.warning(f"No AI result for {package_name} v{current_version}")
            
            return {
                'database': 'MITRE CVE',
                'package_name': package_name,
                'current_version': current_version,
                'search_url': url,
                'found_vulnerabilities': False,  # Will be updated by AI analysis parsing
                'vulnerability_count': 0,  # Will be updated by AI analysis parsing
                'vulnerabilities': [],
                'summary': summary,
                'ai_analysis': ai_result,
                'scanned_at': datetime.now().isoformat(),
                'note': note
            }
            
        except Exception as e:
            self.logger.error(f"Error scanning MITRE CVE for {package_name}: {e}")
            return self._error_result('mitre_cve', package_name, str(e))
    
    async def scan_snyk(self, package_name: str, current_version: str = None) -> Dict[str, Any]:
        """Scan SNYK vulnerability database with AI-powered analysis"""
        try:
            url = f"{self.DATABASES['snyk']['base_url']}/{quote(package_name)}"
            
            # Check if AI analysis is available
            ai_result = None
            if self.ai_analyzer and self.ai_analyzer.is_enabled() and current_version:
                try:
                    self.logger.debug(f"Running AI SNYK analysis for {package_name} v{current_version}")
                    # Use a specialized prompt for SNYK vulnerability analysis
                    ai_result = await self.ai_analyzer.analyze_snyk_result(
                        package_name=package_name,
                        current_version=current_version,
                        snyk_lookup_url=url
                    )
                    self.logger.debug(f"AI SNYK analysis completed: {ai_result}")
                except Exception as e:
                    self.logger.error(f"AI SNYK analysis failed for {package_name}: {e}")
                    ai_result = f"AI analysis failed: {str(e)}"
            
            # Generate result based on AI analysis or fallback to manual review
            if ai_result and "AI analysis not available" not in ai_result and "AI analysis failed" not in ai_result:
                summary = self._standardize_no_risk_message('snyk', ai_result)
                note = f"AI-powered SNYK analysis completed. Original URL for manual verification: {url}"
                self.logger.info(f"✅ AI SNYK analysis completed for {package_name} v{current_version}: {ai_result[:100]}...")
            else:
                summary = f"Manual review required - check {url}"
                note = 'SNYK requires manual review of search results'
                if not self.ai_analyzer or not self.ai_analyzer.is_enabled():
                    note += " (AI analysis not available)"
                elif ai_result:
                    self.logger.warning(f"AI SNYK analysis failed for {package_name}: {ai_result[:100]}...")
                else:
                    self.logger.warning(f"No AI SNYK result for {package_name} v{current_version}")
            
            return {
                'database': 'SNYK',
                'package_name': package_name,
                'current_version': current_version,
                'search_url': url,
                'found_vulnerabilities': False,  # Will be updated by AI analysis parsing
                'vulnerability_count': 0,  # Will be updated by AI analysis parsing
                'vulnerabilities': [],
                'summary': summary,
                'ai_analysis': ai_result,
                'scanned_at': datetime.now().isoformat(),
                'note': note
            }
            
        except Exception as e:
            self.logger.error(f"Error scanning SNYK for {package_name}: {e}")
            return self._error_result('snyk', package_name, str(e))
    
    async def scan_exploit_db(self, package_name: str, current_version: str = None) -> Dict[str, Any]:
        """Scan Exploit Database with AI-powered analysis"""
        try:
            url = f"{self.DATABASES['exploit_db']['base_url']}?text={quote(package_name)}"
            
            # Check if AI analysis is available
            ai_result = None
            if self.ai_analyzer and self.ai_analyzer.is_enabled() and current_version:
                try:
                    self.logger.debug(f"Running AI Exploit Database analysis for {package_name} v{current_version}")
                    # Use a specialized prompt for Exploit Database analysis
                    ai_result = await self.ai_analyzer.analyze_exploit_db_result(
                        package_name=package_name,
                        current_version=current_version,
                        exploit_db_lookup_url=url
                    )
                    self.logger.debug(f"AI Exploit Database analysis completed: {ai_result}")
                except Exception as e:
                    self.logger.error(f"AI Exploit Database analysis failed for {package_name}: {e}")
                    ai_result = f"AI analysis failed: {str(e)}"
            
            # Generate result based on AI analysis or fallback to manual review
            if ai_result and "AI analysis not available" not in ai_result and "AI analysis failed" not in ai_result:
                summary = self._standardize_no_risk_message('exploit_db', ai_result)
                note = f"AI-powered Exploit Database analysis completed. Original URL for manual verification: {url}"
                self.logger.info(f"✅ AI Exploit Database analysis completed for {package_name} v{current_version}: {ai_result[:100]}...")
            else:
                summary = f"Manual review required - check {url}"
                note = 'Exploit Database requires manual review of search results'
                if not self.ai_analyzer or not self.ai_analyzer.is_enabled():
                    note += " (AI analysis not available)"
                elif ai_result:
                    self.logger.warning(f"AI Exploit Database analysis failed for {package_name}: {ai_result[:100]}...")
                else:
                    self.logger.warning(f"No AI Exploit Database result for {package_name} v{current_version}")
            
            return {
                'database': 'Exploit Database',
                'package_name': package_name,
                'current_version': current_version,
                'search_url': url,
                'found_vulnerabilities': False,  # Will be updated by AI analysis parsing
                'vulnerability_count': 0,  # Will be updated by AI analysis parsing
                'vulnerabilities': [],
                'summary': summary,
                'ai_analysis': ai_result,
                'scanned_at': datetime.now().isoformat(),
                'note': note
            }
            
        except Exception as e:
            self.logger.error(f"Error scanning Exploit Database for {package_name}: {e}")
            return self._error_result('exploit_db', package_name, str(e))
    
    async def scan_github_advisory(self, package_name: str, github_url: str = None, current_version: str = None) -> Dict[str, Any]:
        """Scan GitHub Security Advisory with AI-powered analysis"""
        try:
            if github_url and 'github.com' in github_url:
                # If we have a GitHub URL, use the specific repository advisory URL
                repo_match = re.search(r'github\.com/([^/]+)/([^/]+)', github_url)
                if repo_match:
                    owner, repo = repo_match.groups()
                    url = f"https://github.com/{owner}/{repo}/security/advisories"
                else:
                    url = f"{self.DATABASES['github_advisory']['base_url']}?query={quote(f'ecosystem:pip {package_name}')}"
            else:
                url = f"{self.DATABASES['github_advisory']['base_url']}?query={quote(f'ecosystem:pip {package_name}')}"
            
            # Use AI analysis if available and current_version is provided
            if self.ai_analyzer and self.ai_analyzer.is_enabled() and current_version:
                try:
                    ai_result = await self.ai_analyzer.analyze_github_advisory_result(
                        package_name, current_version, url
                    )
                    summary = self._standardize_no_risk_message('github_advisory', ai_result)
                    note = f'AI-powered GitHub Security Advisory analysis for {package_name} v{current_version}'
                except Exception as e:
                    self.logger.warning(f"AI GitHub Security Advisory analysis failed for {package_name}: {e}")
                    ai_result = f"AI analysis failed - manual review required: {str(e)}"
                    summary = f"Manual review required - check {url}"
                    note = 'AI analysis failed - manual review required'
            else:
                ai_result = "Manual review required"
                summary = f"Manual review required - check {url}"
                note = 'GitHub Security Advisory requires manual review of search results'
            
            return {
                'database': 'GitHub Security Advisory',
                'package_name': package_name,
                'search_url': url,
                'found_vulnerabilities': False,
                'vulnerability_count': 0,
                'vulnerabilities': [],
                'summary': summary,
                'ai_analysis': ai_result,
                'scanned_at': datetime.now().isoformat(),
                'note': note
            }
            
        except Exception as e:
            self.logger.error(f"Error scanning GitHub Advisory for {package_name}: {e}")
            return self._error_result('github_advisory', package_name, str(e))
    
    async def scan_all_databases(self, package_name: str, github_url: str = None, current_version: str = None) -> Dict[str, Any]:
        """Scan all databases for a package"""
        self.logger.info(f"Scanning all databases for package: {package_name}")
        
        # Create tasks for all database scans (include current_version for AI analysis)
        tasks = [
            self.scan_nist_nvd(package_name, current_version),
            self.scan_mitre_cve(package_name, current_version),
            self.scan_snyk(package_name, current_version),
            self.scan_exploit_db(package_name, current_version),
            self.scan_github_advisory(package_name, github_url, current_version)
        ]
        
        # Run all scans concurrently
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Process results
        scan_results = {}
        total_vulnerabilities = 0
        databases_with_vulnerabilities = []
        
        database_names = ['nist_nvd', 'mitre_cve', 'snyk', 'exploit_db', 'github_advisory']
        
        for i, result in enumerate(results):
            db_name = database_names[i]
            
            if isinstance(result, Exception):
                self.logger.error(f"Error scanning {db_name}: {result}")
                scan_results[db_name] = self._error_result(db_name, package_name, str(result))
            else:
                scan_results[db_name] = result
                if result.get('found_vulnerabilities', False):
                    total_vulnerabilities += result.get('vulnerability_count', 0)
                    databases_with_vulnerabilities.append(result.get('database', db_name))
        
        # Generate summary
        if total_vulnerabilities > 0:
            summary = f"Found {total_vulnerabilities} vulnerabilities across {len(databases_with_vulnerabilities)} databases"
        else:
            summary = "No vulnerabilities found in any database"
        
        return {
            'package_name': package_name,
            'scan_results': scan_results,
            'total_vulnerabilities': total_vulnerabilities,
            'databases_with_vulnerabilities': databases_with_vulnerabilities,
            'summary': summary,
            'scanned_at': datetime.now().isoformat(),
            'scan_urls': self._build_search_urls(package_name)
        }
    
    def _empty_result(self, database: str, package_name: str, url: str) -> Dict[str, Any]:
        """Generate empty result structure with standardized messages"""
        # Use standardized messages based on database type
        if database == 'github_advisory':
            summary = "No published security advisories"
        else:
            summary = "None found"
            
        return {
            'database': self.DATABASES[database]['name'],
            'package_name': package_name,
            'search_url': url,
            'found_vulnerabilities': False,
            'vulnerability_count': 0,
            'vulnerabilities': [],
            'summary': summary,
            'scanned_at': datetime.now().isoformat()
        }
    
    def _error_result(self, database: str, package_name: str, error_msg: str) -> Dict[str, Any]:
        """Generate error result structure"""
        return {
            'database': self.DATABASES[database]['name'],
            'package_name': package_name,
            'search_url': '',
            'found_vulnerabilities': False,
            'vulnerability_count': 0,
            'vulnerabilities': [],
            'summary': f"Error scanning {self.DATABASES[database]['name']}: {error_msg}",
            'scanned_at': datetime.now().isoformat(),
            'error': error_msg
        }
    
    def _standardize_no_risk_message(self, database: str, ai_result: str = None) -> str:
        """Standardize 'no risk found' messages based on database and AI result"""
        if ai_result and "NOT_FOUND" in ai_result.upper():
            # AI analysis found no vulnerabilities - use standardized message
            if database == 'github_advisory':
                return "No published security advisories"
            else:
                return "None found"
        elif ai_result and "FOUND" in ai_result.upper():
            # AI analysis found vulnerabilities - keep the AI result
            return ai_result
        else:
            # Fallback for manual review or error cases
            return ai_result or "Manual review required"
    
    def generate_recommendations(self, package_name: str, current_version: str, 
                               latest_version: str, vulnerability_results: Dict[str, Any]) -> str:
        """Generate comprehensive recommendations based on all vulnerability scan results (columns M, P, R, T, V)"""
        recommendations = []
        security_findings = []
        
        # Analyze results from all vulnerability databases (M, P, R, T, V)
        scan_results = vulnerability_results.get('scan_results', {})
        
        # Check each database for security findings
        database_findings = {
            'github_advisory': {'found': False, 'count': 0, 'severity': 'NONE'},  # Column M
            'nist_nvd': {'found': False, 'count': 0, 'severity': 'NONE'},         # Column P  
            'mitre_cve': {'found': False, 'count': 0, 'severity': 'NONE'},        # Column R
            'snyk': {'found': False, 'count': 0, 'severity': 'NONE'},             # Column T
            'exploit_db': {'found': False, 'count': 0, 'severity': 'NONE'}        # Column V
        }
        
        # Parse results from each database
        for db_name, result in scan_results.items():
            if db_name in database_findings:
                summary = result.get('summary', '').lower()
                ai_analysis_raw = result.get('ai_analysis', '')
                ai_analysis = ai_analysis_raw.lower() if ai_analysis_raw else ''
                
                # Check if vulnerabilities were found - be very specific to avoid false positives
                vulnerability_found = False
                
                # Check explicit found_vulnerabilities flag
                if result.get('found_vulnerabilities', False):
                    vulnerability_found = True
                
                # Check for actual vulnerability count > 0
                elif result.get('vulnerability_count', 0) > 0:
                    vulnerability_found = True
                
                # Check AI analysis for explicit FOUND indication (but not NOT_FOUND)
                elif ai_analysis and ': found' in ai_analysis and 'not_found' not in ai_analysis:
                    vulnerability_found = True
                
                # Check summary for vulnerability counts
                elif 'found' in summary and 'vulnerabilities' in summary and 'none found' not in summary and 'no published' not in summary:
                    vulnerability_found = True
                
                if vulnerability_found:
                    
                    database_findings[db_name]['found'] = True
                    # Ensure count is at least 1 when vulnerabilities are found
                    vuln_count = result.get('vulnerability_count', 0)
                    database_findings[db_name]['count'] = max(vuln_count, 1)
                    
                    # Extract severity from AI analysis
                    if 'severity: critical' in ai_analysis:
                        database_findings[db_name]['severity'] = 'CRITICAL'
                    elif 'severity: high' in ai_analysis:
                        database_findings[db_name]['severity'] = 'HIGH'
                    elif 'severity: medium' in ai_analysis:
                        database_findings[db_name]['severity'] = 'MEDIUM'
                    elif 'severity: low' in ai_analysis:
                        database_findings[db_name]['severity'] = 'LOW'
        
        # Build security findings summary
        total_vulnerabilities = sum(db['count'] for db in database_findings.values() if db['found'])
        databases_with_findings = [db for db, data in database_findings.items() if data['found']]
        
        # Determine highest severity
        severity_order = ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW', 'NONE']
        highest_severity = 'NONE'
        for severity in severity_order:
            if any(data['severity'] == severity for data in database_findings.values() if data['found']):
                highest_severity = severity
                break
        
        # Generate version update recommendation
        version_update_needed = current_version != latest_version
        if version_update_needed:
            recommendations.append(f"Update from {current_version} to {latest_version}")
        
        # Generate security recommendations
        if total_vulnerabilities > 0:
            security_findings.append(f"SECURITY RISK: {total_vulnerabilities} vulnerabilities found")
            
            # Add severity-based priority
            if highest_severity in ['CRITICAL', 'HIGH']:
                security_findings.append(f"HIGH PRIORITY: {highest_severity} severity vulnerabilities detected")
            
            # Add database-specific findings
            db_names = {
                'github_advisory': 'GitHub Advisory',
                'nist_nvd': 'NIST NVD', 
                'mitre_cve': 'MITRE CVE',
                'snyk': 'SNYK',
                'exploit_db': 'Exploit Database'
            }
            
            finding_details = []
            for db in databases_with_findings:
                if database_findings[db]['found']:
                    count = database_findings[db]['count']
                    severity = database_findings[db]['severity']
                    finding_details.append(f"{db_names.get(db, db)}: {count} ({severity})")
            
            if finding_details:
                security_findings.append(f"Sources: {', '.join(finding_details)}")
            
            security_findings.append("Review security advisories before deployment")
            recommendations.extend(security_findings)
        
        # Return final recommendation
        if not security_findings:
            # No security risks found - return PROCEED only (ignore version updates)
            return "PROCEED"
        else:
            # Security risks found - include version update if needed
            return " | ".join(recommendations)
    
    async def close(self):
        """Close async session"""
        if self.session:
            await self.session.close()
            self.session = None


class SynchronousVulnerabilityScanner:
    """Synchronous wrapper for vulnerability scanning"""
    
    def __init__(self, timeout: int = 30, max_retries: int = 3, openai_api_key: Optional[str] = None,
                 azure_endpoint: Optional[str] = None, azure_model: str = "gpt-4o-mini"):
        self.scanner = VulnerabilityScanner(
            timeout, max_retries, 
            openai_api_key=openai_api_key,
            azure_endpoint=azure_endpoint,
            azure_model=azure_model
        )
    
    def scan_package(self, package_name: str, github_url: str = None, current_version: str = None) -> Dict[str, Any]:
        """Synchronous scan of a single package"""
        return asyncio.run(self.scanner.scan_all_databases(package_name, github_url, current_version))
    
    def scan_packages(self, package_names: List[str]) -> Dict[str, Dict[str, Any]]:
        """Synchronous scan of multiple packages"""
        results = {}
        for package_name in package_names:
            results[package_name] = self.scan_package(package_name)
        return results
    
    def close(self):
        """Close scanner"""
        asyncio.run(self.scanner.close())